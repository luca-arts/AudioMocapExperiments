{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# realsense depth images\n",
    "\n",
    "Code snippets to get stuff done with the realsense cam. This repo is not made for colab, it depends on external hardware\n",
    "\n",
    "## activate right environment\n",
    "conda activate audiomocap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvzone in /home/kaos/anaconda3/envs/audiomocap/lib/python3.8/site-packages (1.5.6)\n",
      "Requirement already satisfied: opencv-python in /home/kaos/anaconda3/envs/audiomocap/lib/python3.8/site-packages (from cvzone) (4.5.5.62)\n",
      "Requirement already satisfied: numpy in /home/kaos/anaconda3/envs/audiomocap/lib/python3.8/site-packages (from cvzone) (1.22.2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# First import the library\n",
    "import pyrealsense2 as rs\n",
    "# Import Numpy for easy array manipulation\n",
    "import numpy as np\n",
    "# Import OpenCV for easy image rendering\n",
    "import cv2\n",
    "import cvzone\n",
    "import statistics\n",
    "#imporrt mediapipe for pose detection\n",
    "import mediapipe as mp\n",
    "# initialize Pose estimator\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "f=[]\n",
    "fpsr=cvzone.FPS()\n",
    "\n",
    "# dataset videos AudioMocapExperiments/notebooks/depthcam/playground/trackColorDepth.ipynb\n",
    "depth = cv2.VideoCapture('../../../dataset1/dataset1/color1flipped.mp4')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (depth.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "ret, frame = depth.read()\n",
    "tracker=cv2.legacy.TrackerMOSSE_create()\n",
    "bbox=cv2.selectROI(\"output\",frame,False)\n",
    "tracker.init(frame ,bbox)\n",
    "\n",
    "\n",
    "def draw(img,bbox):\n",
    "    x,y,w,h=int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3])\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(0,255,255),3,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "while(depth.isOpened()):\n",
    "    ret, frame = depth.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow('Frame',frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "depth.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9YfphDP3mVXuZzcuFzrWl",
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
